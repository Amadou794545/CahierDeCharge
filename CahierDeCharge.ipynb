{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM0rVI8CAkoElqBTNlWfI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amadou794545/CahierDeCharge/blob/main/CahierDeCharge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "QILTBODcaHX8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithme de descente de gradient**"
      ],
      "metadata": {
        "id": "5jOC5N_rTOoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La descente de gradient est une technique mathématique qui permet de trouver de manière itérative les pondérations et les biais qui produisent le modèle avec la perte la plus faible . La descente de gradient permet de trouver la meilleure pondération et le meilleur biais en répétant le processus suivant pour un certain nombre d'itérations définies par l'utilisateur."
      ],
      "metadata": {
        "id": "T6aZAtu8TYvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "savoir mathématique:\n",
        "\n",
        "xt+1= xt– η∆xt"
      ],
      "metadata": {
        "id": "OLqqiaF8U39t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65nQgKVjTKYz",
        "outputId": "e528b222-10c0-4247-efce-62bab3f90752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paramètres optimaux : [-0.18234281  2.43336318]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):\n",
        "    n_samples, n_features = X.shape\n",
        "    theta = np.zeros(n_features)\n",
        "    for _ in range(n_iterations):\n",
        "        gradient = (2/n_samples) * X.T.dot(X.dot(theta) - y)\n",
        "        theta -= learning_rate * gradient\n",
        "    return theta\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([5, 7, 9])\n",
        "theta = gradient_descent(X, y)\n",
        "print(\"Paramètres optimaux :\", theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Régression par force brute**"
      ],
      "metadata": {
        "id": "o0AAJSg3bJUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La régression par force brute est une méthode simple mais coûteuse en calcul pour trouver les paramètres optimaux d'un modèle de régression. Contrairement à des méthodes plus sophistiquées comme la descente de gradient, la force brute consiste à évaluer la fonction de coût pour un grand nombre de combinaisons de paramètres et à choisir celle qui minimise cette fonction."
      ],
      "metadata": {
        "id": "ch32s_MKbN8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "J(θ)=∑\n",
        "i=1\n",
        "n\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −X\n",
        "i\n",
        "​\n",
        " θ)\n",
        "2"
      ],
      "metadata": {
        "id": "r8Z3poB4cwCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "def brute_force_regression(X, y, param_range):\n",
        "    best_theta, best_error = None, float('inf')\n",
        "    for theta in product(param_range, repeat=X.shape[1]):\n",
        "        error = np.sum((X.dot(theta) - y) ** 2)\n",
        "        if error < best_error:\n",
        "            best_theta, best_error = theta, error\n",
        "    return best_theta\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([5, 7, 9])\n",
        "param_range = np.linspace(-10, 10, 100)\n",
        "theta = brute_force_regression(X, y, param_range)\n",
        "print(\"Paramètres optimaux :\", theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lXdlmu2Wq-Y",
        "outputId": "c79809b1-76cd-43a5-f874-3468e53130d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paramètres optimaux : (-0.9090909090909101, 2.929292929292929)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Methode des moindre carré**"
      ],
      "metadata": {
        "id": "kVOKVOySAtMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La méthode des moindres carrés est utilisée pour ajuster un modèle linéaire en minimisant la somme des carrés des erreurs entre les valeurs prédites et les valeurs réelles."
      ],
      "metadata": {
        "id": "jHWcpVWYA3Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "θ=(X\n",
        "T\n",
        " X)\n",
        "−1\n",
        " X\n",
        "T\n",
        " y"
      ],
      "metadata": {
        "id": "YD0_9NHKA5ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def least_squares(X, y):\n",
        "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "    return theta\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([5, 7, 9])\n",
        "theta = least_squares(X, y)\n",
        "print(\"Paramètres optimaux :\", theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NgY_3WJA9R2",
        "outputId": "25bb6211-e92b-478e-efb6-fc810e207aaa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paramètres optimaux : [-1.  3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression lineaire**"
      ],
      "metadata": {
        "id": "QgYW97ICgGXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La régression linéaire est l'une des méthodes les plus fondamentales et les plus utilisées en statistiques et en apprentissage automatique. Elle permet de modéliser la relation entre une variable dépendante (ou cible)\n",
        "Y\n",
        "Y et une ou plusieurs variables indépendantes (ou caractéristiques)\n",
        "X\n",
        "X. L'objectif est de trouver une relation linéaire qui prédit\n",
        "Y\n",
        "Y en fonction de\n",
        "X\n",
        "X."
      ],
      "metadata": {
        "id": "t0ei5pJSgKG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "θ=(X\n",
        "T\n",
        " X)\n",
        "−1\n",
        " X\n",
        "T\n",
        " Y"
      ],
      "metadata": {
        "id": "UO6ikPp_jdin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([5, 7, 9])\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "print(\"Paramètres optimaux :\", model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqgnqNR7gFsZ",
        "outputId": "2141f6e6-e416-473b-a268-df71ce293562"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paramètres optimaux : [1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Régression Polynomiale**"
      ],
      "metadata": {
        "id": "yYUz2cgLBmut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La régression polynomiale modélise la relation entre les variables indépendantes et la variable dépendante par un polynôme."
      ],
      "metadata": {
        "id": "6XVHAhePBqda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y=θ\n",
        "0\n",
        "​\n",
        " +θ\n",
        "1\n",
        "​\n",
        " x+θ\n",
        "2\n",
        "​\n",
        " x\n",
        "2\n",
        " +⋯+θ\n",
        "d\n",
        "​\n",
        " x\n",
        "d\n",
        " +ϵ"
      ],
      "metadata": {
        "id": "gDZ-Q8l5Bs42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1], [2], [3]])\n",
        "y = np.array([5, 7, 9])\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "print(\"Paramètres optimaux :\", model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XihvZZiBzV-",
        "outputId": "d5e5bb62-8023-4f84-eba1-ff65faaceddc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paramètres optimaux : [ 0.00000000e+00  2.00000000e+00 -1.99840144e-15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arbre de Décision**"
      ],
      "metadata": {
        "id": "tPdiK9FiCN6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un arbre de décision divise récursivement l'espace des données en sous-ensembles basés sur des conditions."
      ],
      "metadata": {
        "id": "iiXmBUcACRli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impureté de Gini :\n",
        "G\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "k\n",
        "p\n",
        "i\n",
        "2\n",
        "G=1−∑\n",
        "i=1\n",
        "k\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        ""
      ],
      "metadata": {
        "id": "-UANFqXZCXco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([5, 7, 9])\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X, y)\n",
        "print(\"Prédiction :\", model.predict([[4, 5]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3G93oVBz96",
        "outputId": "238c5e32-c125-4f62-d986-bd1f982ecaef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction : [9.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "YcxJMinxCskt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un Random Forest est un ensemble d'arbres de décision qui combine leurs prédictions pour améliorer la performance."
      ],
      "metadata": {
        "id": "FycMGkqKCv8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([5, 7, 9])\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X, y)\n",
        "print(\"Prédiction :\", model.predict([[4, 5]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ8wysqBCpxb",
        "outputId": "0c3686ed-fedb-4933-8a21-2d8b34e92730"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction : [8.48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Régression Logistique**"
      ],
      "metadata": {
        "id": "3R1OQgbXC95C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La régression logistique modélise la probabilité qu'une instance appartienne à une classe.\n",
        "\n"
      ],
      "metadata": {
        "id": "H-f8vuCoDFK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonction logistique :\n",
        "P\n",
        "(\n",
        "y\n",
        "=\n",
        "1\n",
        "∣\n",
        "X\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "e\n",
        "−\n",
        "X\n",
        "θ\n",
        "P(y=1∣X)=\n",
        "1+e\n",
        "−Xθ\n",
        "\n",
        "\n",
        "\n",
        "Fonction de coût :\n",
        "J\n",
        "(\n",
        "θ\n",
        ")\n",
        "=\n",
        "−\n",
        "1\n",
        "n\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "n\n",
        "[\n",
        "y\n",
        "i\n",
        "log\n",
        "⁡\n",
        "(\n",
        "P\n",
        "(\n",
        "y\n",
        "i\n",
        ")\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "y\n",
        "i\n",
        ")\n",
        "log\n",
        "⁡\n",
        "(\n",
        "1\n",
        "−\n",
        "P\n",
        "(\n",
        "y\n",
        "i\n",
        ")\n",
        ")\n",
        "]\n",
        "J(θ)=−\n",
        "n\n",
        "1\n",
        "​\n",
        " ∑\n",
        "i=1\n",
        "n\n",
        "​\n",
        " [y\n",
        "i\n",
        "​\n",
        " log(P(y\n",
        "i\n",
        "​\n",
        " ))+(1−y\n",
        "i\n",
        "​\n",
        " )log(1−P(y\n",
        "i\n",
        "​\n",
        " ))]"
      ],
      "metadata": {
        "id": "jUuwZVrfDIKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([0, 1, 0])\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "print(\"Prédiction :\", model.predict([[4, 5]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h5p0gxaC8-D",
        "outputId": "332d7aec-5afa-451b-d2a7-92f78687613d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction : [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbours (KNN)"
      ],
      "metadata": {
        "id": "I_ZxC-uiDtL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN classe une instance en fonction des classes de ses k plus proches voisins.\n",
        "\n"
      ],
      "metadata": {
        "id": "qAQulcuVDw02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "y = np.array([0, 1, 0])\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(X, y)\n",
        "print(\"Prédiction :\", model.predict([[4, 5]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlwFAsBaDr59",
        "outputId": "1d5c03fe-fd29-42b4-ca68-5a4b82ae631b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction : [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means"
      ],
      "metadata": {
        "id": "2rG2vJnNE9wG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means partitionne les données en k clusters en minimisant la variance intra-cluster.\n",
        "\n"
      ],
      "metadata": {
        "id": "1602M3-WFLd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonction de coût :\n",
        "J\n",
        "=\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "k\n",
        "∑\n",
        "x\n",
        "∈\n",
        "C\n",
        "i\n",
        "∥\n",
        "x\n",
        "−\n",
        "μ\n",
        "i\n",
        "∥\n",
        "2\n",
        "J=∑\n",
        "i=1\n",
        "k\n",
        "​\n",
        " ∑\n",
        "x∈C\n",
        "i\n",
        "​\n",
        "\n",
        "​\n",
        " ∥x−μ\n",
        "i\n",
        "​\n",
        " ∥\n",
        "2\n",
        " , où\n",
        "μ\n",
        "i\n",
        "μ\n",
        "i\n",
        "​\n",
        "  est le centroïde du cluster\n",
        "C\n",
        "i\n",
        "C\n",
        "i\n",
        "​\n",
        " .\n",
        "\n",
        "Algorithme : Minimise\n",
        "J\n",
        "J en alternant l'affectation des points aux clusters et la mise à jour des centroïdes"
      ],
      "metadata": {
        "id": "NPlwTgEAFU_s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JgOiGM5MFUWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "model = KMeans(n_clusters=2)\n",
        "model.fit(X)\n",
        "print(\"Clusters :\", model.labels_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh9sbX7zD7av",
        "outputId": "ab8b0957-2d0a-4a93-acdd-eb9394ab988e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters : [0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean-Shift"
      ],
      "metadata": {
        "id": "MaYh4fBHFZG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean-Shift identifie les clusters en déplaçant itérativement les points vers le mode de la distribution."
      ],
      "metadata": {
        "id": "I3tCPFVYFb-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1x1cDAhyFfzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MeanShift\n",
        "\n",
        "# Exemple d'utilisation\n",
        "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "model = MeanShift()\n",
        "model.fit(X)\n",
        "print(\"Clusters :\", model.labels_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHh20v0cFgNP",
        "outputId": "d0f8c921-ef7c-4945-96a6-c954d47ea64d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters : [2 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modèles de Mélange Gaussien (GMM)\n",
        "Distribution : Modélise les données comme un mélange de distributions gaussiennes.\n",
        "\n",
        "Fonction de vraisemblance :\n",
        "P\n",
        "(\n",
        "X\n",
        "∣\n",
        "θ\n",
        ")\n",
        "=\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "k\n",
        "π\n",
        "i\n",
        "N\n",
        "(\n",
        "X\n",
        "∣\n",
        "μ\n",
        "i\n",
        ",\n",
        "Σ\n",
        "i\n",
        ")\n",
        "P(X∣θ)=∑\n",
        "i=1\n",
        "k\n",
        "​\n",
        " π\n",
        "i\n",
        "​\n",
        " N(X∣μ\n",
        "i\n",
        "​\n",
        " ,Σ\n",
        "i\n",
        "​\n",
        " ), où\n",
        "π\n",
        "i\n",
        "π\n",
        "i\n",
        "​\n",
        "  est le poids de la composante\n",
        "i\n",
        "i."
      ],
      "metadata": {
        "id": "Xh7ST4S4FpdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Méthode Bayésienne\n",
        "Théorème de Bayes :\n",
        "P\n",
        "(\n",
        "y\n",
        "∣\n",
        "X\n",
        ")\n",
        "=\n",
        "P\n",
        "(\n",
        "X\n",
        "∣\n",
        "y\n",
        ")\n",
        "P\n",
        "(\n",
        "y\n",
        ")\n",
        "P\n",
        "(\n",
        "X\n",
        ")\n",
        "P(y∣X)=\n",
        "P(X)\n",
        "P(X∣y)P(y)\n",
        "​\n",
        " .\n",
        "\n",
        "Classification : Choisit la classe\n",
        "y\n",
        "y qui maximise\n",
        "P\n",
        "(\n",
        "y\n",
        "∣\n",
        "X\n",
        ")\n",
        "P(y∣X).\n",
        "\n"
      ],
      "metadata": {
        "id": "g7yo8pmPFvpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machines à Vecteurs de Support (SVM)\n",
        "Hyperplan : Trouve l'hyperplan\n",
        "w\n",
        "T\n",
        "x\n",
        "+\n",
        "b\n",
        "=\n",
        "0\n",
        "w\n",
        "T\n",
        " x+b=0 qui maximise la marge entre les classes.\n",
        "\n",
        "Fonction de coût :\n",
        "min\n",
        "⁡\n",
        "1\n",
        "2\n",
        "∥\n",
        "w\n",
        "∥\n",
        "2\n",
        "+\n",
        "C\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "n\n",
        "max\n",
        "⁡\n",
        "(\n",
        "0\n",
        ",\n",
        "1\n",
        "−\n",
        "y\n",
        "i\n",
        "(\n",
        "w\n",
        "T\n",
        "x\n",
        "i\n",
        "+\n",
        "b\n",
        ")\n",
        ")\n",
        "min\n",
        "2\n",
        "1\n",
        "​\n",
        " ∥w∥\n",
        "2\n",
        " +C∑\n",
        "i=1\n",
        "n\n",
        "​\n",
        " max(0,1−y\n",
        "i\n",
        "​\n",
        " (w\n",
        "T\n",
        " x\n",
        "i\n",
        "​\n",
        " +b))."
      ],
      "metadata": {
        "id": "j58jaZOEFwg9"
      }
    }
  ]
}